AWSTemplateFormatVersion: "2010-09-09"

Description: Amazon Transcribe Live Call Analytics - LCA SSM Parameters

Parameters:
  # Required
  LCAStackName:
    Type: String
    Description: LCA Stack Name

  LLMPromptSummaryTemplate:
    Type: String
    Description: >-
      Prompt to use to generate insights for a call. This can be a single string where an LLM returns a string,
      or a single string where the LLM returns a JSON object with key/value pairs, or a string that contains
      a JSON Object with key/value pairs, where the LLM will run one inference on each key/value pair with the value
      containing the prompt. Use {transcript} as a placeholder for where the call transcript will be injected.
    Default: >-
      Human: Answer all the questions below as a json object with key value pairs, the key is provided, and answer as the value, based on the transcript. Only return json. Use gender neutral pronouns.
      <br><questions> 
      <br>Summary: Generate a short summary of the call.
      <br>Topics: List the topics discussed in the transcript. Choose from one or more of these or make one up (iphone issue, billing issue, cancellation).
      <br>Follow-Up Actions: In a markdown list, provide the follow-up actions the agent needs to take after the call. 
      <br></questions>  
      <br><transcript> 
      <br>{transcript} 
      <br></transcript> 
      <br>Assistant: Here is the JSON object with the answers to the questions:

Resources:
  LLMPromptSummaryTemplateParameter:
    Type: "AWS::SSM::Parameter"
    Properties:
      Name: !Sub "${LCAStackName}-LLMPromptSummaryTemplate"
      Type: String
      Description: >
        Prompt to use to generate insights for a call. This can be a single string where an LLM returns a string,
        or a single string where the LLM returns a JSON object with key/value pairs, or a string that contains
        a JSON Object with key/value pairs, where the LLM will run one inference on each key/value pair with the value
        containing the prompt. Use {transcript} as a placeholder for where the call transcript will be injected.
      Value: !Ref LLMPromptSummaryTemplate

Outputs:
  LLMPromptSummaryTemplateParameter:
    Value: !Ref LLMPromptSummaryTemplateParameter